{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd00edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:53:38.744853Z",
     "iopub.status.busy": "2025-12-14T15:53:38.744594Z",
     "iopub.status.idle": "2025-12-14T15:56:22.326251Z",
     "shell.execute_reply": "2025-12-14T15:56:22.325548Z"
    },
    "papermill": {
     "duration": 163.5868,
     "end_time": "2025-12-14T15:56:22.328198",
     "exception": false,
     "start_time": "2025-12-14T15:53:38.741398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Generating features...\n",
      "Training on 2017824 rows with features: ['county', 'product_type', 'is_business', 'eic_count', 'installed_capacity', 'lowest_price_per_mwh', 'highest_price_per_mwh', 'euros_per_mwh', 'temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid', 'cloudcover_total', '10_metre_u_wind_component', '10_metre_v_wind_component', 'direct_solar_radiation', 'hour', 'dayofweek', 'month', 'is_holiday', 'hour_sin', 'hour_cos']\n",
      "[15:54:10] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"device\" } are not used.\n",
      "\n",
      "[0]\tvalidation_0-rmse:378.81325\n",
      "[100]\tvalidation_0-rmse:102.59892\n",
      "[200]\tvalidation_0-rmse:87.70264\n",
      "[300]\tvalidation_0-rmse:80.60616\n",
      "[400]\tvalidation_0-rmse:75.14251\n",
      "[500]\tvalidation_0-rmse:71.01000\n",
      "[600]\tvalidation_0-rmse:67.44845\n",
      "[700]\tvalidation_0-rmse:64.67036\n",
      "[800]\tvalidation_0-rmse:62.39110\n",
      "[900]\tvalidation_0-rmse:60.35809\n",
      "[999]\tvalidation_0-rmse:58.43324\n",
      "[15:55:15] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"device\" } are not used.\n",
      "\n",
      "[0]\tvalidation_0-rmse:1223.78557\n",
      "[100]\tvalidation_0-rmse:183.76288\n",
      "[200]\tvalidation_0-rmse:151.86673\n",
      "[300]\tvalidation_0-rmse:137.02287\n",
      "[400]\tvalidation_0-rmse:127.02864\n",
      "[500]\tvalidation_0-rmse:120.18350\n",
      "[600]\tvalidation_0-rmse:114.81689\n",
      "[700]\tvalidation_0-rmse:110.46398\n",
      "[800]\tvalidation_0-rmse:106.68184\n",
      "[900]\tvalidation_0-rmse:103.22038\n",
      "[999]\tvalidation_0-rmse:100.77267\n",
      "Training Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import enefit\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/predict-energy-behavior-of-prosumers/\"\n",
    "ESTONIA_HOLIDAYS = [\n",
    "    \"2022-01-01\", \"2022-02-24\", \"2022-04-15\", \"2022-04-17\", \"2022-05-01\",\n",
    "    \"2022-06-05\", \"2022-06-23\", \"2022-06-24\", \"2022-08-20\", \"2022-12-24\",\n",
    "    \"2022-12-25\", \"2022-12-26\", \"2023-01-01\", \"2023-02-24\", \"2023-04-07\",\n",
    "    \"2023-04-09\", \"2023-05-01\", \"2023-05-28\", \"2023-06-23\", \"2023-06-24\",\n",
    "    \"2023-08-20\", \"2023-12-24\", \"2023-12-25\", \"2023-12-26\"\n",
    "]\n",
    "\n",
    "def upsample_daily_to_hourly(df: pd.DataFrame, date_col: str) -> pd.DataFrame:\n",
    "    if df.empty: return df\n",
    "    df_hourly = df.copy()\n",
    "    df_hourly[date_col] = pd.to_datetime(df_hourly[date_col])\n",
    "    df_hourly['datetime'] = df_hourly[date_col].apply(\n",
    "        lambda x: [x + pd.Timedelta(hours=i) for i in range(24)]\n",
    "    )\n",
    "    df_hourly = df_hourly.explode('datetime').drop(columns=[date_col])\n",
    "    return df_hourly\n",
    "\n",
    "def process_forecast_weather(df_forecast: pd.DataFrame, location_map: dict) -> pd.DataFrame:\n",
    "    if df_forecast.empty: return pd.DataFrame()\n",
    "    df = df_forecast.copy()\n",
    "    \n",
    "    df['county'] = [location_map.get((round(x,1), round(y,1)), -1) for x, y in zip(df['latitude'], df['longitude'])]\n",
    "    df = df[df['county'] != -1]\n",
    "    \n",
    "    df['origin_datetime'] = pd.to_datetime(df['origin_datetime'])\n",
    "    df['origin_date'] = df['origin_datetime'].dt.floor('D') \n",
    "    df['forecast_datetime'] = df['origin_date'] + pd.to_timedelta(df['hours_ahead'], unit='h')\n",
    "    \n",
    "    exclude = ['latitude', 'longitude', 'hours_ahead', 'forecast_datetime', 'origin_datetime', 'origin_date', 'county', 'data_block_id']\n",
    "    feats = [c for c in df.columns if c not in exclude]\n",
    "    \n",
    "    df_grouped = df.groupby(['county', 'forecast_datetime'])[feats].mean().reset_index()\n",
    "    df_grouped.rename(columns={'forecast_datetime': 'datetime'}, inplace=True)\n",
    "    return df_grouped\n",
    "\n",
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    dt = df[\"datetime\"].dt\n",
    "    df[\"hour\"] = dt.hour.astype(\"int8\")\n",
    "    df[\"month\"] = dt.month.astype(\"int8\")\n",
    "    df[\"dayofweek\"] = dt.dayofweek.astype(\"int8\")\n",
    "    \n",
    "    holidays = pd.to_datetime(ESTONIA_HOLIDAYS)\n",
    "    df[\"is_holiday\"] = df[\"datetime\"].dt.normalize().isin(holidays).astype(\"int8\")\n",
    "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
    "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
    "    return df\n",
    "\n",
    "# --- FEATURE GENERATION ---\n",
    "\n",
    "def generate_features(\n",
    "    df_data, df_client, df_gas, df_elec, df_forecast, location_map\n",
    "):\n",
    "    df_data['datetime'] = pd.to_datetime(df_data['datetime'])\n",
    "    \n",
    "    # 1. Client Data\n",
    "    df_client_h = upsample_daily_to_hourly(df_client, 'date')\n",
    "    if not df_client_h.empty:\n",
    "        df_data = df_data.merge(\n",
    "            df_client_h[['county', 'product_type', 'is_business', 'datetime', 'eic_count', 'installed_capacity']],\n",
    "            on=['county', 'product_type', 'is_business', 'datetime'], \n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "    # This handles the case where client data is slightly delayed\n",
    "    df_data['eic_count'] = df_data.groupby(['county', 'is_business', 'product_type'])['eic_count'].ffill().fillna(0)\n",
    "    df_data['installed_capacity'] = df_data.groupby(['county', 'is_business', 'product_type'])['installed_capacity'].ffill().fillna(0)\n",
    "\n",
    "    # 2. Gas Prices\n",
    "    df_gas_h = upsample_daily_to_hourly(df_gas, 'forecast_date')\n",
    "    if not df_gas_h.empty:\n",
    "        df_data = df_data.merge(df_gas_h[['datetime', 'lowest_price_per_mwh', 'highest_price_per_mwh']], on='datetime', how='left')\n",
    "    df_data['lowest_price_per_mwh'] = df_data['lowest_price_per_mwh'].ffill().fillna(0)\n",
    "    df_data['highest_price_per_mwh'] = df_data['highest_price_per_mwh'].ffill().fillna(0)\n",
    "\n",
    "    if not df_elec.empty:\n",
    "        df_elec = df_elec.rename(columns={'forecast_date': 'datetime'})\n",
    "        df_elec['datetime'] = pd.to_datetime(df_elec['datetime'])\n",
    "        df_data = df_data.merge(df_elec[['datetime', 'euros_per_mwh']], on='datetime', how='left')\n",
    "        df_data['euros_per_mwh'] = df_data['euros_per_mwh'].ffill().fillna(0)\n",
    "\n",
    "    df_weather = process_forecast_weather(df_forecast, location_map)\n",
    "    if not df_weather.empty:\n",
    "        df_data = df_data.merge(df_weather, on=['county', 'datetime'], how='left')\n",
    "        # Fill weather NaNs (if any) with mean\n",
    "        feat_cols = [c for c in df_weather.columns if c not in ['county', 'datetime']]\n",
    "        df_data[feat_cols] = df_data[feat_cols].fillna(df_data[feat_cols].mean())\n",
    "\n",
    "    df_data = add_time_features(df_data)\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "print(\"Loading data...\")\n",
    "df_train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "df_client = pd.read_csv(DATA_DIR + \"client.csv\")\n",
    "df_gas = pd.read_csv(DATA_DIR + \"gas_prices.csv\")\n",
    "df_elec = pd.read_csv(DATA_DIR + \"electricity_prices.csv\")\n",
    "df_forecast = pd.read_csv(DATA_DIR + \"forecast_weather.csv\")\n",
    "df_map = pd.read_csv(DATA_DIR + \"weather_station_to_county_mapping.csv\")\n",
    "\n",
    "df_map = df_map.dropna(subset=['latitude', 'longitude', 'county'])\n",
    "loc_map = dict(zip(zip(round(df_map['latitude'],1), round(df_map['longitude'],1)), df_map['county']))\n",
    "\n",
    "# --- PREPARE TRAINING ---\n",
    "print(\"Generating features...\")\n",
    "df_all = generate_features(df_train, df_client, df_gas, df_elec, df_forecast, loc_map)\n",
    "df_all = df_all.dropna(subset=['target']) # Only drop rows with no target during training\n",
    "\n",
    "# split models\n",
    "common_feats = [\n",
    "    'county', 'product_type', 'is_business', \n",
    "    'eic_count', 'installed_capacity',\n",
    "    'lowest_price_per_mwh', 'highest_price_per_mwh', 'euros_per_mwh',\n",
    "    'temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid', 'cloudcover_total',\n",
    "    '10_metre_u_wind_component', '10_metre_v_wind_component', 'direct_solar_radiation',\n",
    "    'hour', 'dayofweek', 'month', 'is_holiday', 'hour_sin', 'hour_cos'\n",
    "]\n",
    "# Filter features that actually exist in dataframe\n",
    "features = [c for c in common_feats if c in df_all.columns]\n",
    "\n",
    "print(f\"Training on {len(df_all)} rows with features: {features}\")\n",
    "\n",
    "# Train Model 0 (Production)\n",
    "X0 = df_all[df_all['is_consumption'] == 0][features]\n",
    "y0 = df_all[df_all['is_consumption'] == 0]['target']\n",
    "model_prod = xgb.XGBRegressor(\n",
    "    n_estimators=1000, learning_rate=0.05, max_depth=6, \n",
    "    early_stopping_rounds=50, enable_categorical=True, device=\"cuda\", tree_method=\"hist\"\n",
    ")\n",
    "model_prod.fit(X0, y0, eval_set=[(X0, y0)], verbose=100)\n",
    "\n",
    "# Train Model 1 (Consumption)\n",
    "X1 = df_all[df_all['is_consumption'] == 1][features]\n",
    "y1 = df_all[df_all['is_consumption'] == 1]['target']\n",
    "model_cons = xgb.XGBRegressor(\n",
    "    n_estimators=1000, learning_rate=0.05, max_depth=6, \n",
    "    early_stopping_rounds=50, enable_categorical=True, device=\"cuda\", tree_method=\"hist\"\n",
    ")\n",
    "model_cons.fit(X1, y1, eval_set=[(X1, y1)], verbose=100)\n",
    "\n",
    "print(\"Training Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5dfe3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:56:22.335862Z",
     "iopub.status.busy": "2025-12-14T15:56:22.335591Z",
     "iopub.status.idle": "2025-12-14T15:56:22.502065Z",
     "shell.execute_reply": "2025-12-14T15:56:22.501394Z"
    },
    "papermill": {
     "duration": 0.172267,
     "end_time": "2025-12-14T15:56:22.504149",
     "exception": false,
     "start_time": "2025-12-14T15:56:22.331882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Storage class to accumulate API data\n",
    "class HistoryStorage:\n",
    "    def __init__(self):\n",
    "        self.client = df_client.copy()\n",
    "        self.gas = df_gas.copy()\n",
    "        self.elec = df_elec.copy()\n",
    "        self.forecast = df_forecast.copy()\n",
    "        \n",
    "    def update(self, client_new, gas_new, elec_new, forecast_new):\n",
    "        # Concatenate and de-duplicate (keep latest)\n",
    "        self.client = pd.concat([self.client, client_new]).drop_duplicates(subset=['county', 'is_business', 'product_type', 'date'], keep='last')\n",
    "        self.gas = pd.concat([self.gas, gas_new]).drop_duplicates(subset=['forecast_date'], keep='last')\n",
    "        self.elec = pd.concat([self.elec, elec_new]).drop_duplicates(subset=['forecast_date'], keep='last')\n",
    "        self.forecast = pd.concat([self.forecast, forecast_new]).drop_duplicates(subset=['latitude', 'longitude', 'hours_ahead', 'origin_datetime'], keep='last')\n",
    "\n",
    "storage = HistoryStorage()\n",
    "\n",
    "env = enefit.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c7e14d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:56:22.510892Z",
     "iopub.status.busy": "2025-12-14T15:56:22.510616Z",
     "iopub.status.idle": "2025-12-14T15:57:17.573993Z",
     "shell.execute_reply": "2025-12-14T15:57:17.573118Z"
    },
    "papermill": {
     "duration": 55.071184,
     "end_time": "2025-12-14T15:57:17.578222",
     "exception": false,
     "start_time": "2025-12-14T15:56:22.507038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference...\n",
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "Inference finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting inference...\")\n",
    "\n",
    "for (test, revealed_targets, client, historical_weather,\n",
    "        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n",
    "    storage.update(client, gas_prices, electricity_prices, forecast_weather)\n",
    "    \n",
    "    test['datetime'] = pd.to_datetime(test['prediction_datetime'])\n",
    "    X_test = generate_features(\n",
    "        test, \n",
    "        storage.client, \n",
    "        storage.gas, \n",
    "        storage.elec, \n",
    "        storage.forecast, \n",
    "        loc_map\n",
    "    )\n",
    "    \n",
    "    X_test_vals = X_test[features]\n",
    "    \n",
    "    cat_cols = ['county', 'product_type', 'is_business', 'is_consumption']\n",
    "    for col in cat_cols:\n",
    "        if col in X_test_vals.columns:\n",
    "            X_test_vals[col] = X_test_vals[col].astype('category')\n",
    "    \n",
    "    mask_cons = X_test['is_consumption'] == 1\n",
    "    preds = np.zeros(len(X_test))\n",
    "    \n",
    "    # Predict Consumption\n",
    "    if mask_cons.any():\n",
    "        X_cons = X_test_vals[mask_cons]\n",
    "        dtest_cons = xgb.DMatrix(X_cons, enable_categorical=True, feature_names=features)\n",
    "        preds[mask_cons] = model_cons.get_booster().predict(dtest_cons)\n",
    "        \n",
    "    # Predict Production\n",
    "    if (~mask_cons).any():\n",
    "        X_prod = X_test_vals[~mask_cons]\n",
    "        dtest_prod = xgb.DMatrix(X_prod, enable_categorical=True, feature_names=features)\n",
    "        preds[~mask_cons] = model_prod.get_booster().predict(dtest_prod)\n",
    "        \n",
    "    sample_prediction['target'] = np.clip(preds, 0, None)\n",
    "    \n",
    "    env.predict(sample_prediction)\n",
    "\n",
    "print(\"Inference finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100af192",
   "metadata": {
    "papermill": {
     "duration": 0.00256,
     "end_time": "2025-12-14T15:57:17.583536",
     "exception": false,
     "start_time": "2025-12-14T15:57:17.580976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7292407,
     "sourceId": 57236,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 222.136439,
   "end_time": "2025-12-14T15:57:18.003644",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T15:53:35.867205",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
